# funciones:
# orquestacion de pipeline completo
# configuracion de par√°metros
# ejecuci√≥n secuencial

import os
import sys
import argparse
import time
from datetime import datetime

# Agregar el directorio src al path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Importar m√≥dulos del proyecto
from preprocess import DataPreprocessor
from train_models import ModelTrainer
from evaluate import ModelEvaluator

class MLPipeline:
    def __init__(self, config=None):
        self.config = config or self.get_default_config()
        self.preprocessor = None
        self.trainer = None
        self.evaluator = None
        
        # Crear directorios necesarios
        self.create_directories()
    
    def get_default_config(self):
        """Configuraci√≥n por defecto del pipeline"""
        return {
            'data_path': 'data/raw/',
            'target_variable': 'anemia',  # opciones: 'anemia', 'desnutricion', 'riesgo'
            'test_size': 0.2,
            'val_size': 0.2,
            'random_state': 42,
            'save_processed': True,
            'save_models': True,
            'create_plots': True
        }
    
    def create_directories(self):
        """Crear estructura de directorios necesaria"""
        directories = [
            'data/processed',
            'models/base_models',
            'models/stacking',
            'results/metrics',
            'results/plots',
            'results/reports'
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def step_1_preprocess(self):
        """Paso 1: Preprocesamiento de datos"""
        print("\n" + "="*60)
        print("PASO 1: PREPROCESAMIENTO DE DATOS")
        print("="*60)
        
        start_time = time.time()
        
        try:
            # Inicializar preprocessor
            self.preprocessor = DataPreprocessor(data_path=self.config['data_path'])
            
            # Procesar datos
            data = self.preprocessor.process_data(
                target=self.config['target_variable'],
                save_processed=self.config['save_processed']
            )
            
            if data is None:
                raise Exception("Error en el preprocesamiento de datos")
            
            X_train, X_val, X_test, y_train, y_val, y_test = data
            
            print(f"\n‚úÖ Preprocesamiento completado exitosamente!")
            print(f"‚è±Ô∏è  Tiempo: {time.time() - start_time:.2f} segundos")
            print(f"üìä Datos finales:")
            print(f"   - Entrenamiento: {X_train.shape}")
            print(f"   - Validaci√≥n: {X_val.shape}")
            print(f"   - Prueba: {X_test.shape}")
            
            return True
            
        except Exception as e:
            print(f"\n‚ùå Error en preprocesamiento: {e}")
            return False
    
    def step_2_train(self):
        """Paso 2: Entrenamiento de modelos"""
        print("\n" + "="*60)
        print("PASO 2: ENTRENAMIENTO DE MODELOS")
        print("="*60)
        
        start_time = time.time()
        
        try:
            # Inicializar trainer
            self.trainer = ModelTrainer(random_state=self.config['random_state'])
            
            # Entrenar modelos
            results = self.trainer.train_stacking_ensemble()
            
            if results is None:
                raise Exception("Error en el entrenamiento de modelos")
            
            ensemble, base_results, stacking_results = results
            
            print(f"\n‚úÖ Entrenamiento completado exitosamente!")
            print(f"‚è±Ô∏è  Tiempo: {time.time() - start_time:.2f} segundos")
            
            return True
            
        except Exception as e:
            print(f"\n‚ùå Error en entrenamiento: {e}")
            return False
    
    def step_3_evaluate(self):
        """Paso 3: Evaluaci√≥n detallada"""
        print("\n" + "="*60)
        print("PASO 3: EVALUACI√ìN DETALLADA")
        print("="*60)
        
        start_time = time.time()
        
        try:
            # Inicializar evaluador
            self.evaluator = ModelEvaluator()
            
            # Realizar evaluaci√≥n completa
            results = self.evaluator.comprehensive_evaluation()
            
            if results is None:
                raise Exception("Error en la evaluaci√≥n")
            
            print(f"\n‚úÖ Evaluaci√≥n completada exitosamente!")
            print(f"‚è±Ô∏è  Tiempo: {time.time() - start_time:.2f} segundos")
            
            return True, results
            
        except Exception as e:
            print(f"\n‚ùå Error en evaluaci√≥n: {e}")
            return False, None
    
    def generate_summary_report(self, evaluation_results=None):
        """Generar reporte resumen del proyecto"""
        print("\n" + "="*60)
        print("GENERANDO REPORTE RESUMEN")
        print("="*60)
        
        try:
            report_lines = []
            
            # Encabezado
            report_lines.extend([
                "="*80,
                "REPORTE FINAL DEL PROYECTO",
                "Aplicaci√≥n de Algoritmos de Machine Learning para la",
                "Predicci√≥n del Estado Nutricional Infantil en Arequipa",
                "="*80,
                f"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                f"Variable objetivo: {self.config['target_variable']}",
                ""
            ])
            
            # Configuraci√≥n utilizada
            report_lines.extend([
                "üìã CONFIGURACI√ìN DEL EXPERIMENTO:",
                f"  ‚Ä¢ Tama√±o de prueba: {self.config['test_size']*100:.1f}%",
                f"  ‚Ä¢ Tama√±o de validaci√≥n: {self.config['val_size']*100:.1f}%",
                f"  ‚Ä¢ Semilla aleatoria: {self.config['random_state']}",
                f"  ‚Ä¢ Variable objetivo: {self.config['target_variable']}",
                ""
            ])
            
            # Metodolog√≠a
            report_lines.extend([
                "üî¨ METODOLOG√çA:",
                "  ‚Ä¢ Fuente de datos: SIEN-HIS (Sistema de Informaci√≥n del Estado Nutricional)",
                "  ‚Ä¢ Poblaci√≥n: Ni√±os de 5-11 a√±os en Arequipa, 2024",
                "  ‚Ä¢ T√©cnica: Stacking Ensemble Learning",
                "  ‚Ä¢ Modelos base: Random Forest, XGBoost, SVM",
                "  ‚Ä¢ Meta-modelo: Regresi√≥n Log√≠stica",
                "  ‚Ä¢ Validaci√≥n: Validaci√≥n cruzada estratificada (5 folds)",
                ""
            ])
            
            # Resultados (si est√°n disponibles)
            if evaluation_results:
                metrics = evaluation_results['metrics']
                clinical_metrics = evaluation_results.get('clinical_metrics')
                
                report_lines.extend([
                    "üìä RESULTADOS PRINCIPALES:",
                    f"  ‚Ä¢ Exactitud (Accuracy): {metrics['accuracy']:.4f}",
                    f"  ‚Ä¢ Precisi√≥n: {metrics['precision']:.4f}",
                    f"  ‚Ä¢ Sensibilidad (Recall): {metrics['recall']:.4f}",
                    f"  ‚Ä¢ F1-Score: {metrics['f1_score']:.4f}",
                ])
                
                if 'auc_roc' in metrics:
                    report_lines.append(f"  ‚Ä¢ AUC-ROC: {metrics['auc_roc']:.4f}")
                
                if clinical_metrics:
                    report_lines.extend([
                        "",
                        "üè• M√âTRICAS CL√çNICAS:",
                        f"  ‚Ä¢ Sensibilidad cl√≠nica: {clinical_metrics['sensitivity']:.4f}",
                        f"  ‚Ä¢ Especificidad cl√≠nica: {clinical_metrics['specificity']:.4f}",
                        f"  ‚Ä¢ Valor Predictivo Positivo: {clinical_metrics['ppv']:.4f}",
                        f"  ‚Ä¢ Valor Predictivo Negativo: {clinical_metrics['npv']:.4f}",
                    ])
                
                report_lines.append("")
            
            # Archivos generados
            report_lines.extend([
                "  ARCHIVOS GENERADOS:",
                "  Datos procesados:",
                "    ‚Ä¢ data/processed/merged_data.csv - Dataset unificado",
                "    ‚Ä¢ data/processed/train_data.csv - Datos de entrenamiento",
                "    ‚Ä¢ data/processed/val_data.csv - Datos de validaci√≥n", 
                "    ‚Ä¢ data/processed/test_data.csv - Datos de prueba",
                "",
                "  Modelos entrenados:",
                "    ‚Ä¢ models/base_models/ - Modelos individuales (RF, XGB, SVM)",
                "    ‚Ä¢ models/stacking/ - Modelo de stacking ensemble",
                "",
                "  Resultados y evaluaci√≥n:",
                "    ‚Ä¢ results/metrics/ - M√©tricas detalladas",
                "    ‚Ä¢ results/plots/ - Visualizaciones",
                "    ‚Ä¢ results/reports/ - Reportes detallados",
                ""
            ])
            
            # Conclusiones y recomendaciones
            report_lines.extend([
                "üéØ CONCLUSIONES:",
                "  ‚Ä¢ Se implement√≥ exitosamente un modelo de stacking ensemble",
                "  ‚Ä¢ El modelo combina las fortalezas de tres algoritmos diferentes",
                "  ‚Ä¢ Los datos del SIEN-HIS proporcionan informaci√≥n valiosa para la predicci√≥n",
                "  ‚Ä¢ La correcci√≥n por altitud es crucial en el contexto de Arequipa",
                "",
                "üí° RECOMENDACIONES PARA USO CL√çNICO:",
                "  ‚Ä¢ Validar el modelo con datos de otras regiones",
                "  ‚Ä¢ Considerar actualizaci√≥n peri√≥dica con nuevos datos",
                "  ‚Ä¢ Integrar con sistemas de informaci√≥n hospitalaria",
                "  ‚Ä¢ Capacitar al personal de salud en interpretaci√≥n de resultados",
                "",
                "üìù PARA EL ART√çCULO DE INVESTIGACI√ìN:",
                "  ‚Ä¢ Los resultados demuestran la viabilidad del stacking ensemble",
                "  ‚Ä¢ La metodolog√≠a es replicable y escalable",
                "  ‚Ä¢ Los datos reales de Arequipa aportan validez externa",
                "  ‚Ä¢ Se puede comparar con enfoques tradicionales de diagn√≥stico",
                ""
            ])
            
            # Limitaciones
            report_lines.extend([
                "‚ö†Ô∏è  LIMITACIONES:",
                "  ‚Ä¢ Datos limitados a un a√±o (2024) y una regi√≥n (Arequipa)",
                "  ‚Ä¢ Posible sesgo de selecci√≥n en establecimientos de salud",
                "  ‚Ä¢ Requiere validaci√≥n prospectiva",
                "  ‚Ä¢ Dependencia de calidad de datos del SIEN-HIS",
                "",
                "="*80
            ])
            
            # Guardar reporte
            report_text = '\n'.join(report_lines)
            
            os.makedirs('results/reports', exist_ok=True)
            with open('results/reports/project_summary.txt', 'w', encoding='utf-8') as f:
                f.write(report_text)
            
            print("‚úÖ Reporte resumen generado: results/reports/project_summary.txt")
            return report_text
            
        except Exception as e:
            print(f"‚ùå Error generando reporte: {e}")
            return None
    
    def run_complete_pipeline(self):
        """Ejecutar pipeline completo"""
        print("üöÄ INICIANDO PIPELINE COMPLETO DE MACHINE LEARNING")
        print("Predicci√≥n del Estado Nutricional Infantil - Arequipa")
        print("="*80)
        
        pipeline_start = time.time()
        
        # Paso 1: Preprocesamiento
        if not self.step_1_preprocess():
            print("\nüí• Pipeline interrumpido en el preprocesamiento")
            return False
        
        # Paso 2: Entrenamiento
        if not self.step_2_train():
            print("\nüí• Pipeline interrumpido en el entrenamiento")
            return False
        
        # Paso 3: Evaluaci√≥n
        success, evaluation_results = self.step_3_evaluate()
        if not success:
            print("\nüí• Pipeline interrumpido en la evaluaci√≥n")
            return False
        
        # Generar reporte final
        self.generate_summary_report(evaluation_results)
        
        # Tiempo total
        total_time = time.time() - pipeline_start
        
        print(f"\nüéâ ¬°PIPELINE COMPLETADO EXITOSAMENTE!")
        print(f"‚è±Ô∏è  Tiempo total: {total_time//60:.0f}m {total_time%60:.0f}s")
        print(f"üìÇ Revisa la carpeta 'results/' para todos los outputs")
        
        return True
    
    def run_single_step(self, step):
        """Ejecutar un paso individual"""
        if step == 'preprocess':
            return self.step_1_preprocess()
        elif step == 'train':
            return self.step_2_train()
        elif step == 'evaluate':
            success, results = self.step_3_evaluate()
            return success
        else:
            print(f"‚ùå Paso '{step}' no reconocido")
            return False

def main():
    """Funci√≥n principal con argumentos de l√≠nea de comandos"""
    parser = argparse.ArgumentParser(
        description='Pipeline de Machine Learning para Predicci√≥n de Estado Nutricional Infantil'
    )
    
    parser.add_argument(
        '--step', 
        choices=['preprocess', 'train', 'evaluate', 'complete'],
        default='complete',
        help='Paso espec√≠fico a ejecutar (default: complete)'
    )
    
    parser.add_argument(
        '--target',
        choices=['anemia', 'desnutricion', 'riesgo'],
        default='anemia',
        help='Variable objetivo a predecir (default: anemia)'
    )
    
    parser.add_argument(
        '--data-path',
        default='data/raw/',
        help='Ruta a los datos originales (default: data/raw/)'
    )
    
    parser.add_argument(
        '--random-state',
        type=int,
        default=42,
        help='Semilla para reproducibilidad (default: 42)'
    )
    
    args = parser.parse_args()
    
    # Configuraci√≥n personalizada
    config = {
        'data_path': args.data_path,
        'target_variable': args.target,
        'test_size': 0.2,
        'val_size': 0.2,
        'random_state': args.random_state,
        'save_processed': True,
        'save_models': True,
        'create_plots': True
    }
    
    # Inicializar pipeline
    pipeline = MLPipeline(config)
    
    # Ejecutar seg√∫n el argumento
    if args.step == 'complete':
        success = pipeline.run_complete_pipeline()
    else:
        success = pipeline.run_single_step(args.step)
    
    if success:
        print(f"\n‚úÖ Proceso '{args.step}' completado exitosamente")
    else:
        print(f"\n‚ùå Error en el proceso '{args.step}'")
        sys.exit(1)

if __name__ == "__main__":
    main()